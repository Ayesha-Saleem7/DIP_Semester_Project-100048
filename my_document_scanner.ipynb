{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80681e32",
   "metadata": {},
   "source": [
    "# Advanced Document Scanner (Notebook Version)\n",
    "\n",
    "This notebook demonstrates **each image processing method step-by-step**  \n",
    "Every method includes its **working name and purpose** for easy understanding.\n",
    "\n",
    "---\n",
    "### Libraries Used\n",
    "- OpenCV\n",
    "- NumPy\n",
    "- Matplotlib\n",
    "- PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4bfb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT REQUIRED LIBRARIES\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35887c98",
   "metadata": {},
   "source": [
    "## 1. Point Ordering Method  \n",
    "**Method Name:** `order_points`  \n",
    "**Purpose:**  \n",
    "Reorders detected contour points into a fixed order:\n",
    "- Top-Left\n",
    "- Top-Right\n",
    "- Bottom-Right\n",
    "- Bottom-Left  \n",
    "Required for correct perspective transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]      # Top-left\n",
    "    rect[2] = pts[np.argmax(s)]      # Bottom-right\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]   # Top-right\n",
    "    rect[3] = pts[np.argmax(diff)]   # Bottom-left\n",
    "    return rect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece0857a",
   "metadata": {},
   "source": [
    "## 2. Perspective Transformation  \n",
    "**Method Name:** `four_point_transform`  \n",
    "**Purpose:**  \n",
    "- Removes camera angle distortion  \n",
    "- Converts document to top-down scanned view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    widthA = np.linalg.norm(br - bl)\n",
    "    widthB = np.linalg.norm(tr - tl)\n",
    "    maxWidth = int(max(widthA, widthB))\n",
    "\n",
    "    heightA = np.linalg.norm(tr - br)\n",
    "    heightB = np.linalg.norm(tl - bl)\n",
    "    maxHeight = int(max(heightA, heightB))\n",
    "\n",
    "    if maxWidth < 50 or maxHeight < 50:\n",
    "        return None\n",
    "\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]\n",
    "    ], dtype=\"float32\")\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    return cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adf841",
   "metadata": {},
   "source": [
    "## 3. Document Detection  \n",
    "**Method Name:** `detect_document_advanced`  \n",
    "\n",
    "### Processing Pipeline:\n",
    "1. Image Resize  \n",
    "2. Grayscale Conversion  \n",
    "3. Gaussian Blur (Noise Reduction)  \n",
    "4. Canny Edge Detection  \n",
    "5. Morphological Closing  \n",
    "6. Contour Detection  \n",
    "7. Polygon Approximation (4 edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744db502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_document_advanced(image):\n",
    "    orig = image.copy()\n",
    "    ratio = image.shape[0] / 800.0\n",
    "\n",
    "    resized = cv2.resize(image, (int(image.shape[1]/ratio), 800))\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise reduction\n",
    "    blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "\n",
    "    # Edge detection\n",
    "    edged = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Morphological close\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    closed = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    cnts, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    for c in cnts[:10]:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            return orig, approx.reshape(4,2) * ratio, True\n",
    "\n",
    "    return orig, None, False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14152164",
   "metadata": {},
   "source": [
    "## 4. Document Enhancement  \n",
    "**Method Name:** `enhance_document`  \n",
    "\n",
    "### Enhancement Steps:\n",
    "1. Grayscale Conversion  \n",
    "2. Non-Local Means Denoising  \n",
    "3. CLAHE Contrast Enhancement  \n",
    "4. Sharpening Filter  \n",
    "5. Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4339a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_document(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Noise removal\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
    "\n",
    "    # Contrast enhancement\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    contrasted = clahe.apply(denoised)\n",
    "\n",
    "    # Sharpening\n",
    "    kernel = np.array([[-1,-1,-1],[-1,9,-1],[-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(contrasted, -1, kernel)\n",
    "\n",
    "    # Binarization\n",
    "    return cv2.adaptiveThreshold(\n",
    "        sharpened, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY, 21, 10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be63f0",
   "metadata": {},
   "source": [
    "## 5. Run Complete Pipeline  \n",
    "Replace `sample.jpg` with your image file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input image\n",
    "image = cv2.imread(\"sample.jpg\")\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aff00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig, contour, found = detect_document_advanced(image)\n",
    "\n",
    "if found:\n",
    "    warped = four_point_transform(orig, contour)\n",
    "    scanned = enhance_document(warped)\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(scanned, cmap=\"gray\")\n",
    "    plt.title(\"Final Scanned Document\")\n",
    "    plt.axis(\"off\")\n",
    "else:\n",
    "    print(\"Document not detected\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
